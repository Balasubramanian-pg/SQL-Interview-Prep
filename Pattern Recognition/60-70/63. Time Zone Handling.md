## Pattern: Managing data across different time zones.

**The Gist**: You've got timestamps from all over the world, but your database needs to handle them consistently, and then show them to users in *their* local time. It's about translating time, not just data.

> [!IMPORTANT]
> Time zone handling is not optional for global applications. Mismanaging time zones leads to incorrect data, missed deadlines, and a broken user experience. This isn't just a "nice to have," it's critical.

### Decomposition Strategy: (The only sane way to handle time)

#### 1. Store timestamps in a standard time zone (UTC).

*   This is the golden rule, no cap. Everything in your database should be stored in UTC (Coordinated Universal Time). It's the universal truth. Why? Because it avoids all the Daylight Saving Time drama and local time zone offsets. It's the neutral ground.

#### 2. Convert to appropriate display time zones.

*   Only when you're about to show the time to a user, *then* you convert it from UTC to their specific local time zone. This means you also need to know *what* their local time zone is (e.g., stored in their user profile).
*   SQL databases have functions (like `AT TIME ZONE` in PostgreSQL or `CONVERT_TZ` in MySQL) for this.

#### 3. Handle Daylight Saving Time transitions.

*   This is where UTC storage shines. If your data is in UTC, you don't have to worry about the database adjusting for DST when you store it. When you convert *to* a local time zone, the database *should* automatically handle DST for that specific zone, because it knows the rules.
*   > [!WARNING]
    > Trusting `NOW()` or `CURRENT_TIMESTAMP()` in your application code without explicitly setting the time zone or converting to UTC before saving is a recipe for disaster. Always be explicit, always convert to UTC upon entry.

#### 4. Perform time-based calculations across zones.

*   When you need to count events in "local morning hours" for users in different zones, you first convert their event times to *their* local zone, then extract the hour, then count.
*   If you're comparing events globally, compare them in UTC. Don't mix and match local times for global comparisons. That's just chaos.

---

### Example: "Analyze customer activity across different time zones."

**What we've got**:
*   `user_events` table: `user_id`, `event_timestamp` (stored in UTC, always!).
*   `users` table: `id`, `user_timezone` (e.g., 'America/New_York', 'Europe/London').

**Sample Data (Imagine these are UTC timestamps, `user_timezone` is 'America/Los_Angeles' for user 1, 'Europe/Berlin' for user 2):**

`user_events`:
| user_id | event_timestamp          |
| :------ | :----------------------- |
| 1       | 2023-10-27 10:00:00+00   |
| 1       | 2023-10-27 14:00:00+00   |
| 2       | 2023-10-27 08:00:00+00   |
| 2       | 2023-10-27 15:00:00+00   |

`users`:
| id | user_timezone         |
| :-- | :-------------------- |
| 1  | America/Los_Angeles   |
| 2  | Europe/Berlin         |

**The SQL (Making sense of global time):**

#### 1. Convert to user's local time zone (for display/intermediate step)

```sql
SELECT
    ue.user_id,
    ue.event_timestamp AT TIME ZONE 'UTC' AS utc_timestamp, -- Just to confirm it's UTC
    -- This is the magic: Convert the UTC timestamp to the user's local time zone.
    ue.event_timestamp AT TIME ZONE u.user_timezone AS local_timestamp,
    -- Then, extract the hour from that *local* timestamp.
    EXTRACT(HOUR FROM ue.event_timestamp AT TIME ZONE u.user_timezone) AS local_hour
FROM user_events ue
JOIN users u ON ue.user_id = u.id;
```

**Execution Trace (example with sample data):**

*   **User 1, `2023-10-27 10:00:00+00` (UTC)** with `user_timezone` 'America/Los_Angeles' (PDT, UTC-7):
    *   `10:00:00+00` becomes `03:00:00` (local time).
    *   `local_hour` extracted is `3`.
*   **User 2, `2023-10-27 08:00:00+00` (UTC)** with `user_timezone` 'Europe/Berlin' (CEST, UTC+2):
    *   `08:00:00+00` becomes `10:00:00` (local time).
    *   `local_hour` extracted is `10`.

#### 2. Find peak activity hours by user's local time

```sql
SELECT
    -- Directly extract the hour after converting to local time for each event.
    EXTRACT(HOUR FROM ue.event_timestamp AT TIME ZONE u.user_timezone) AS local_hour,
    COUNT(*) AS event_count
FROM user_events ue
JOIN users u ON ue.user_id = u.id
GROUP BY local_hour -- Grouping by the *local* hour.
ORDER BY event_count DESC;
```

> [!NOTE]
> This query gives you the overall peak hours, irrespective of *which* time zone the user is in. So, "3 AM local time" might be peak if a lot of users are active then, even if those 3 AMs are different UTC times. This is super useful for understanding user behavior.

#### 3. Compare activity across time zones (more detailed breakdown)

```sql
-- First CTE: Calculate event counts for each local hour, *per time zone*.
WITH local_hours AS (
    SELECT
        u.user_timezone,
        EXTRACT(HOUR FROM ue.event_timestamp AT TIME ZONE u.user_timezone) AS local_hour,
        COUNT(*) AS event_count
    FROM user_events ue
    JOIN users u ON ue.user_id = u.id
    GROUP BY u.user_timezone, local_hour -- Grouping by both time zone AND local hour.
)

-- Final SELECT: Calculate what percentage each local hour contributes to that timezone's total activity.
SELECT
    lh.user_timezone,
    lh.local_hour,
    lh.event_count,
    -- Window function: SUM(event_count) OVER (PARTITION BY user_timezone) gets total events for THAT timezone.
    lh.event_count * 100.0 / SUM(lh.event_count) OVER (PARTITION BY lh.user_timezone) AS pct_of_timezone_activity
FROM local_hours lh
ORDER BY lh.user_timezone, lh.local_hour;
```

> [!TIP]
> This last query is great for seeing if, say, 'America/New_York' users are most active at 9 AM local, while 'Asia/Tokyo' users are most active at 10 PM local. It standardizes the *time perception* for each user group.

> [!WARNING]
> Using `TIMESTAMP WITHOUT TIME ZONE` in your database for storing events is a massive red flag. Always use `TIMESTAMP WITH TIME ZONE` or convert to/from UTC explicitly upon entry/exit. Relying on the server's local time setting is a fragile approach that *will* break. Seriously, don't do it.
