# Pattern: Complex text pattern matching and extraction.

**The Gist**: You're looking for specific pieces of information hidden within unstructured text, like finding Waldo but, like, 10 Waldos at once, all dressed differently. You use rules (regex) to grab them.

> [!NOTE]
> This pattern is essential when dealing with semi-structured or unstructured text data (like logs, user comments, scraped web content) where you need to parse out specific fields that aren't in a neat column.

### Decomposition Strategy: (How to make sense of the text chaos)

#### 1. Define regex patterns for target text.

*   This is the first, most critical step. You need to write regular expressions (regex) that precisely match the *exact* pieces of text you want to extract.
*   **Example**: `\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}` for a timestamp. This defines what a timestamp *looks like* in your text.
*   > [!IMPORTANT]
    > Regex is powerful but can be cryptic. Test your patterns rigorously on sample data to ensure they match *only* what you intend to extract and don't miss anything. A tiny mistake in regex can lead to huge data extraction errors.

#### 2. Extract matched components.

*   Once you have your patterns, you use SQL functions (like `SUBSTRING...FROM...` with regex in PostgreSQL, or `REGEXP_SUBSTR` in Oracle/MySQL, or `REGEXP_EXTRACT` in BigQuery) to pull out the matched bits.
*   You'll often extract multiple pieces of data from the same log entry.

#### 3. Apply transformations to extracted parts.

*   Sometimes, what you extract isn't quite ready for primetime. You might need to:
    *   `CAST` a string (like a number or date) into its proper data type.
    *   `TRIM` whitespace.
    *   `LOWER()` or `UPPER()` case for consistency.
    *   `REPLACE()` characters.

#### 4. Handle edge cases and validation.

*   What if a pattern *doesn't* exist in a particular text entry? Your extraction function might return `NULL`. Your query needs to account for this.
*   What if the extracted data needs to be validated (e.g., is this *actually* a valid IP address or email format)? You can use more regex for validation (`~*` operator in PostgreSQL).
*   > [!WARNING]
    > Never, ever trust raw user input. Always sanitize it (remove potentially malicious HTML/script tags) before displaying or storing, especially if it's going back to a web page. Regex can help with basic sanitization, but for serious security, rely on server-side libraries.

---

### Example: "Extract structured data from log entry text."

**What we've got**: An `application_logs` table with `log_id` and `log_entry` (a long text string).

**Sample `log_entry`:**
`2023-10-27 14:35:01 [INFO] User UID:ABC12345 from 192.168.1.10 connected successfully.`
`2023-10-27 14:35:05 [DEBUG] Processing request for UID:DEF67890. Payload size: 128KB.`
`2023-10-27 14:35:10 [ERROR] Failed to connect to DB from 10.0.0.5. Error: Timeout.`
`2023-10-27 14:35:12 [WARNING] Unknown user attempt from 203.0.113.44. (No UID)`

**The SQL (PostgreSQL specific regex functions):**

```sql
SELECT
    log_id,
    log_entry,
    -- Step 2: Extract timestamp pattern at the beginning of the line.
    -- '^' anchors to the start of the string.
    SUBSTRING(log_entry FROM '^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})') AS timestamp_str,
    -- Step 3: Convert the extracted string to an actual timestamp data type.
    CAST(SUBSTRING(log_entry FROM '^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})') AS TIMESTAMP) AS parsed_timestamp,
    -- Step 2: Extract log level (DEBUG, INFO, etc.)
    -- '\[...\]' matches the brackets literally. '(DEBUG|INFO...)' is a capturing group for the level.
    SUBSTRING(log_entry FROM '\[(DEBUG|INFO|WARNING|ERROR|CRITICAL)\]') AS log_level,
    -- Step 2: Extract IP address.
    -- '\d{1,3}\.' matches 1-3 digits followed by a dot. Repeated 3 times, then 1-3 digits.
    SUBSTRING(log_entry FROM '(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})') AS ip_address,
    -- Step 2: Extract user ID (UID: followed by alphanumeric characters).
    -- 'UID:' matches literally. '([A-Za-z0-9]+)' captures the actual ID.
    SUBSTRING(log_entry FROM 'UID:([A-Za-z0-9]+)') AS user_id,
    -- Step 2: Extract the actual message content.
    -- '\[(DEBUG|INFO|...)\]\s+' matches the level tag and any following whitespace.
    -- '(.*)$' captures everything after that till the end of the line.
    SUBSTRING(log_entry FROM '\[(DEBUG|INFO|WARNING|ERROR|CRITICAL)\]\s+(.*)$') AS message
FROM application_logs;
```

**Execution Trace (example for `2023-10-27 14:35:01 [INFO] User UID:ABC12345 from 192.168.1.10 connected successfully.`):**

*   `timestamp_str`: `2023-10-27 14:35:01`
*   `parsed_timestamp`: `2023-10-27 14:35:01.000000` (as a `TIMESTAMP` object)
*   `log_level`: `INFO`
*   `ip_address`: `192.168.1.10`
*   `user_id`: `ABC12345`
*   `message`: `User UID:ABC12345 from 192.168.1.10 connected successfully.`

---

#### Advanced validation and cleaning

This section shows how to further use regex for data quality.

```sql
SELECT
    ud.email,
    -- Step 4: Validate if email has a valid format. Returns TRUE/FALSE.
    -- This regex is a common, basic email validation pattern.
    ud.email ~* '^[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}$' AS is_valid_email,
    -- Step 2: Extract the domain from the email.
    -- '@([^@]+)$' captures everything after the last '@' till the end.
    SUBSTRING(ud.email FROM '@([^@]+)$') AS domain,
    ud.user_input,
    -- Step 4: Sanitize inputs (remove potentially malicious script tags).
    -- 'REGEXP_REPLACE' replaces all occurrences of a pattern with something else (here, an empty string).
    -- 'gi' flags mean global (all occurrences) and case-insensitive.
    REGEXP_REPLACE(ud.user_input, '<script.*?>.*?</script>', '', 'gi') AS sanitized_input
FROM user_data ud;
```

> [!CAUTION]
> Regex for complex tasks like email validation or robust HTML sanitization can be incredibly complex and still not cover all edge cases. While these examples are good for basic understanding, for production-grade security, rely on well-tested libraries in your application code rather than solely on SQL regex. It's about being practical and not trying to reinvent the wheel for critical security tasks.

> [!TIP]
> Use a regex tester tool (there are tons online) to build and test your patterns. It's much easier than debugging them directly in SQL. A good regex pattern is precise, but it's not always obvious just by looking at it.
