## 16. What is **denormalization**, and how does it affect query performance?

**Denormalization** is the process of intentionally introducing redundancy into a database by combining tables or adding duplicate data. This goes against the principles of **normalization** (which aims to minimize redundancy) but is done to **improve query performance**, especially in read-heavy systems.

## **Why Denormalize?**

### **1. Faster Reads**
- **Normalized databases** require complex joins to retrieve related data, which can slow down queries.
- **Denormalized databases** store related data together, reducing the need for joins and speeding up read operations.

### **2. Simplified Queries**
- Fewer joins mean simpler, faster queries—ideal for reporting, analytics, or dashboards.

### **3. Reduced Overhead**
- Joins are expensive. Denormalization cuts down on CPU and I/O usage for read operations.

## **How Does It Affect Performance?**

### **✅ Benefits**
- **Faster SELECT queries**: Data is pre-joined and stored in one place.
- **Better for read-heavy workloads**: Ideal for OLAP (Online Analytical Processing) systems.
- **Reduced join complexity**: Simplifies application logic.

### **❌ Trade-offs**
- **Slower writes**: Inserts/updates/deletes become slower because redundant data must be updated in multiple places.
- **Increased storage**: Duplicate data consumes more disk space.
- **Risk of inconsistency**: Redundant data can become out of sync if not managed carefully.

## **When to Use Denormalization?**
- **Read-heavy applications** (e.g., reporting, dashboards).
- **OLAP systems** (data warehouses, analytics).
- **Caching frequently accessed data** (e.g., user profiles with embedded order history).

## **Example**
### **Normalized Schema**
- **Tables**: `users`, `orders`, `products` (linked via foreign keys).
- **Query**: Requires joins to fetch a user’s orders and product details.

### **Denormalized Schema**
- **Single table**: `user_orders` with user details, order history, and product names duplicated.
- **Query**: Single-table lookup—no joins needed.

### **Key Callouts**

<ins>**Callout 1: Performance vs. Normalization**</ins>
- Normalization optimizes for **data integrity** and **write efficiency**.
- Denormalization optimizes for **read speed** and **simplicity**.

<ins>**Callout 2: Use Cases**</ins>
- **Denormalize** for reporting, analytics, or read-heavy apps.
- **Avoid denormalization** for OLTP (transactional) systems where write speed and consistency are critical.

<ins>**Callout 3: Hybrid Approach**</ins>
- Many systems use a mix: normalized tables for transactions, denormalized tables/views for reporting.

<ins>**Callout 4: Alternatives**</ins>
- Use **indexes**, **materialized views**, or **caching** before denormalizing.

<ins>**Callout 5: Maintenance**</ins>
- Denormalized data requires careful synchronization (e.g., triggers, application logic).

**Trade-off Summary:**
| Scenario          | Normalization          | Denormalization        |
|-------------------|------------------------|------------------------|
| **Writes**        | Fast                   | Slower                 |
| **Reads**         | Slower (joins)         | Faster                 |
| **Storage**       | Efficient              | Redundant              |
| **Consistency**   | High                   | Risk of inconsistency  |
